{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction\n",
    "The following notebook aims at reproducing the __empirical results__ from the paper [\"Feature learning in neural networks and kernel machines that recursively learn features\"](https://arxiv.org/abs/2212.13881). The experiments aim at showing that RFMs are able to learn extremely similar features to those learned by neural networks. The reproduction focuses on 3 experiments:\n",
    "1. __Key result__: RFMs and neural networks learn similar features\n",
    "2. __Tabular data__: RFMs outperforms most models on tabular data\n",
    "3. __Special phenomena__: Both neural networks and RFMs exhibit grokking and simplicity biases behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from rfm import rfm, eval_rfm\n",
    "from nn import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Key result: RFMs and neural networks learn similar features\n",
    "The original paper shows that RFMs and neural networks learn similar features on the [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset. The following code just focuses on that, as it's the main empirical results that motivates the usefulness of RFMs in the study of neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 5636\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "SIZE = 96\n",
    "transform = transforms.Compose([transforms.Resize([SIZE, SIZE]), transforms.ToTensor()])\n",
    "\n",
    "celeba_path = \"~/datasets/\"\n",
    "trainset = torchvision.datasets.CelebA(\n",
    "    root=celeba_path, split=\"train\", transform=transform, download=True\n",
    ")\n",
    "\n",
    "trainset = get_balanced_data(trainset)\n",
    "trainset, valset = split(trainset, p=0.8)\n",
    "\n",
    "print(\"Train Size: \", len(trainset), \"Val Size: \", len(valset))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=1\n",
    ")\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=100, shuffle=False, num_workers=1\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CelebA(\n",
    "    root=celeba_path, split=\"test\", transform=transform, download=True\n",
    ")\n",
    "\n",
    "testset = get_balanced_data(testset)\n",
    "print(\"Test Size: \", len(testset))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=512, shuffle=False, num_workers=1\n",
    ")\n",
    "\n",
    "# Optional name for saving model\n",
    "name = \"glasses\"\n",
    "\n",
    "# Code for training rfm\n",
    "rfm.rfm(trainloader, valloader, testloader, name=name, reg=1e-3, iters=1)\n",
    "\n",
    "# Code for training neural network\n",
    "t.train_network(trainloader, valloader, testloader, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tabular data: RFMs outperforms most models on tabular data\n",
    "Reportedly RFMs get better accuracy on tabular benchmark datasets than other models, such as XGBoost and MLPs. This sections reproduces those results on a couple of benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Special phenomena: Both neural networks and RFMs exhibit grokking and simplicity biases behaviours\n",
    "Finally, it is shown that RFMs exhibit grokking and simplicity biases, as neural networks do. Briefly:\n",
    "- __Grokking__ is a dramatic increase in test accuracy when training past the point of overfitting. Arguably, it happens when the model learns a latent algirith to solve the task (e.g. if the data is algorighmically generated)\n",
    "- __Simplicity bias__ is the fact that networks rely on simpler features to solve the task, even if more complex features are available. This could happen because neural networks tend to be as linear as possible.\n",
    "This last section reproduces the results for RFMs and neural networks on grokking and simplicity biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
